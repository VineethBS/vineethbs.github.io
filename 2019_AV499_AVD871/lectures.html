<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="lectures.html" class="current">Lectures</a></div>
<div class="menu-item"><a href="project.html">Project</a></div>
<div class="menu-item"><a href="classtest_exams.html">Class&nbsp;tests&nbsp;&amp;&nbsp;Exams</a></div>
</td>
<td id="layout-content">
<h1>Applied Markov decision processes &amp; Reinforcement Learning (AV499 &amp; AVD871)</h1>
<div class="infoblock">
<div class="blockcontent">
<h2>Textbook and References</h2>
<ul>
<li><p><b>Richard S. Sutton and Andrew G. Barto. Reinforcement learning: An introduction. MIT press, 2018.</b></p>
</li>
<li><p>Dimitri P. Bertsekas, Dynamic programming and optimal control. Vols. I and II, Athena scientific, 2005.</p>
</li>
<li><p>Sheldon M. Ross. Applied probability models with optimization applications. Courier Corporation, 2013.</p>
</li>
<li><p>Sheldon M. Ross. Introduction to stochastic dynamic programming. Academic press, 2014.</p>
</li>
<li><p>Csaba Szepesv√°ri, Algorithms for Reinforcement Learning, Morgan and Claypool, 2010.</p>
</li>
<li><p>Dimitri P. Bertsekas, Reinforcement learning and Optimal Control, Athena Scientific, 2019.</p>
</li>
<li><p>Dimitri P. Bertsekas and John Tsitsiklis - Introduction to Probability</p>
</li>
<li><p>Bruce Hajek - An exploration of random processes for engineers</p>
</li>
<li><p>Anurag Kumar - Discrete time stochastic processes (lecture notes for an engineering curriculum)</p>
</li>
</ul>
</div></div>
<h2>Lecture Schedule</h2>
<table id="LectureSchedule"><tr class="r1"><td>
No </td><td class="c1"> Date </td><td class="c1"> Topic </td><td class="c1"> Homework/Assignments </td></tr>
<tr class="r2"><td>
1 </td><td class="c1"> 03-01-2019 </td><td class="c1"> Introduction and Course Review </td><td class="c1"> </td></tr>
<tr class="r2"><td>
2 </td><td class="c1"> 04-01-2019 </td><td class="c1"> Definition of System, Example of an optimization problem, Bellman&rsquo;s optimality criterion </td><td class="c1"> <a href="ProgrammingAssignments/progassgn_1.pdf">Programming Assignment 1</a> </td></tr>
<tr class="r2"><td>
3 </td><td class="c1"> 07-01-2019 </td><td class="c1"> Definition of Horizon, Optimization problem, Shortest path problem, Dijkstra&rsquo;s algorithm </td><td class="c1"> </td></tr>
<tr class="r2"><td>
4 </td><td class="c1"> 10-01-2019 </td><td class="c1"> Optimization problem, illustrative introduction to dynamic programming </td><td class="c1"> </td></tr>
<tr class="r2"><td>
5 </td><td class="c1"> 11-01-2019 </td><td class="c1"> Dynamic programming algorithm, Complexity of dynamic programming </td><td class="c1"> </td></tr>
<tr class="r2"><td>
6 </td><td class="c1"> 14-01-2019 </td><td class="c1"> Dynamic programming examples </td><td class="c1"> </td></tr>
<tr class="r2"><td>
7 </td><td class="c1"> 18-01-2019 </td><td class="c1"> Generalizing the system evolution function </td><td class="c1"> </td></tr>
<tr class="r2"><td>
8 </td><td class="c1"> 19-01-2019 </td><td class="c1"> System evolution using conditional probabilities </td><td class="c1"> <a href="ProgrammingAssignments/progassgn_2.pdf">Programming Assignment 2</a> <br /> <a href="Assignments/Assignment_1.pdf">Assignment 1</a></td></tr>
<tr class="r2"><td>
9 </td><td class="c1"> 19-01-2019 </td><td class="c1"> Markov property </td><td class="c1"> <a href="Notes/Note-19012019.pdf">Note</a> </td></tr>
<tr class="r2"><td>
10 </td><td class="c1"> 24-01-2019 </td><td class="c1"> Examples of Markov chains, Markov chains with actions </td><td class="c1"> </td></tr>
<tr class="r2"><td>
11 </td><td class="c1"> 25-01-2019 </td><td class="c1"> Markov chains with actions, evolution, random rewards </td><td class="c1"> <a href="ProgrammingAssignments/progassgn_3.pdf">Programming Assignment 3</a> </td></tr>
<tr class="r2"><td>
12 </td><td class="c1"> 28-01-2019 </td><td class="c1"> Expected total reward, returns, and discounting </td><td class="c1"> </td></tr>
<tr class="r2"><td>
13 </td><td class="c1"> 31-01-2019 </td><td class="c1"> Markov decision processes - examples </td><td class="c1"> </td></tr>
<tr class="r2"><td>
14 </td><td class="c1"> 01-02-2019 </td><td class="c1"> Solution of 1-horizon problem, Solution of 2-horizon problem, Feedback policies </td><td class="c1"> </td></tr>
<tr class="r2"><td>
15 </td><td class="c1"> 07-02-2019 </td><td class="c1"> Value functions and q functions </td><td class="c1"> </td></tr>
<tr class="r2"><td>
16 </td><td class="c1"> 08-02-2019 </td><td class="c1"> Example for value function computation, solution of 2-horizon problem </td><td class="c1"> </td></tr>
<tr class="r2"><td>
</td><td class="c1"> 11-02-2019 </td><td class="c1"> Tutorial </td><td class="c1"> <a href="Tutorials/AV499-Tutorial1.pdf">Tutorial 1</a><br /> <a href="Tutorials/AV499-q4-soln.pdf">Solution</a> </td></tr>
<tr class="r2"><td>
</td><td class="c1"> 15-02-2019 </td><td class="c1"> Discussion of Quiz 1 answers </td><td class="c1"> </td></tr>
<tr class="r2"><td>
17 </td><td class="c1"> 18-02-2019 </td><td class="c1"> Optimality of state-dependent deterministic policies - finite horizon </td><td class="c1"> </td></tr>
<tr class="r2"><td>
18 </td><td class="c1"> 25-02-2019 </td><td class="c1"> Optimality of state-dependent policies - infinite horizon case </td><td class="c1"> </td></tr>
<tr class="r2"><td>
19 </td><td class="c1"> 28-02-2019 </td><td class="c1"> Solution of finite horizon MDP - algorithm </td><td class="c1"> <a href="ProgrammingAssignments/progassgn_4.pdf">Programming Assignment 4</a><br /> <a href="Assignments/Assignment_2.pdf">Assignment 2</a></td></tr>
<tr class="r2"><td>
20 </td><td class="c1"> 01-03-2019 </td><td class="c1"> Solution of infinite horizon MDP - the optimality equation, Value iteration </td><td class="c1"> <a href="ProgrammingAssignments/progassgn_5.pdf">Programming Assignment 5</a><br /> <a href="ProgrammingAssignments/value_iteration_demonstration.m">Value iteration example</a></td></tr>
<tr class="r2"><td>
21 </td><td class="c1"> 07-03-2019 </td><td class="c1"> Convergence of value iteration, Policy improvement </td><td class="c1"> </td></tr>
<tr class="r2"><td>
22 </td><td class="c1"> 08-03-2019 </td><td class="c1"> Policy iteration, convergence of policy iteration </td><td class="c1"> <a href="ProgrammingAssignments/progassgn_6.pdf">Programming Assignment 6</a><br /> <a href="ProgrammingAssignments/policy_iteration_demonstration.m">Policy iteration example</a></td></tr>
<tr class="r2"><td>
23 </td><td class="c1"> 09-03-2019 </td><td class="c1"> Introduction to RL, k-armed Bandit problems, regret, exploration vs exploitation </td><td class="c1"> <a href="ProgrammingAssignments/progassgn_7.pdf">Programming Assignment 7</a><br /> <a href="ProgrammingAssignments/simulate_system.m">System</a>, <a href="ProgrammingAssignments/epsilon_greedy_agent.m">Agent</a></td></tr>
<tr class="r2"><td>
24 </td><td class="c1"> 09-03-2019 </td><td class="c1"> Bandit algorithms - greedy, epsilon-greedy, soft-max, incremental implementation </td><td class="c1"> </td></tr>
<tr class="r2"><td>
25 </td><td class="c1"> 11-03-2019 </td><td class="c1"> Bandit algorithms - UCB </td><td class="c1"> </td></tr>
<tr class="r2"><td>
26 </td><td class="c1"> 15-03-2019 </td><td class="c1"> Introduction to Bayesian bandits, Contextual bandits </td><td class="c1"> </td></tr>
<tr class="r2"><td>
</td><td class="c1"> 16-03-2019 </td><td class="c1"> Tutorial </td><td class="c1"> <a href="Tutorials/AV499-Tutorial2.pdf">Tutorial 2</a><br /> <a href="Tutorials/AV499-Tutorial-Bandits.pdf">Questions on Bandits</a> </td></tr>
<tr class="r2"><td>
27 </td><td class="c1"> 18-03-2019 </td><td class="c1"> The full reinforcement learning problem, Monte carlo evaluation </td><td class="c1"> </td></tr>
<tr class="r2"><td>
28 </td><td class="c1"> 22-03-2019 </td><td class="c1"> First visit and every visit Monte carlo </td><td class="c1"> </td></tr>
<tr class="r2"><td>
</td></tr></table>
<div id="footer">
<div id="footer-text">
Page generated 2019-03-27 08:16:00 IST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
