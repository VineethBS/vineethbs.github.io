<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="lectures.html" class="current">Lectures</a></div>
<div class="menu-item"><a href="classtest_exams.html">Class&nbsp;tests&nbsp;&amp;&nbsp;Exams</a></div>
</td>
<td id="layout-content">
<h1>Applied Markov decision processes &amp; Reinforcement Learning (AV499 &amp; AVD871)</h1>
<div class="infoblock">
<div class="blockcontent">
<h2>Textbook and References</h2>
<ul>
<li><p><b>Richard S. Sutton and Andrew G. Barto. Reinforcement learning: An introduction. MIT press, 2018.</b></p>
</li>
<li><p>Dimitri P. Bertsekas, Dynamic programming and optimal control. Vols. I and II, Athena scientific, 2005.</p>
</li>
<li><p>Sheldon M. Ross. Applied probability models with optimization applications. Courier Corporation, 2013.</p>
</li>
<li><p>Sheldon M. Ross. Introduction to stochastic dynamic programming. Academic press, 2014.</p>
</li>
<li><p>Csaba Szepesv√°ri, Algorithms for Reinforcement Learning, Morgan and Claypool, 2010.</p>
</li>
<li><p>Dimitri P. Bertsekas, Reinforcement learning and Optimal Control, Athena Scientific, 2019.</p>
</li>
<li><p>Dimitri P. Bertsekas and John Tsitsiklis - Introduction to Probability</p>
</li>
<li><p>Bruce Hajek - An exploration of random processes for engineers</p>
</li>
<li><p>Anurag Kumar - Discrete time stochastic processes (lecture notes for an engineering curriculum)</p>
</li>
</ul>
</div></div>
<h2>Lecture Schedule</h2>
<table id="LectureSchedule"><tr class="r1"><td>
No </td><td class="c1"> Date </td><td class="c1"> Topic </td><td class="c1"> Homework/Assignments </td></tr>
<tr class="r2"><td>
1 </td><td class="c1"> 03-01-2019 </td><td class="c1"> Introduction and Course Review </td><td class="c1"> </td></tr>
<tr class="r2"><td>
2 </td><td class="c1"> 04-01-2019 </td><td class="c1"> Definition of System, Example of an optimization problem, Bellman&rsquo;s optimality criterion </td><td class="c1"> <a href="ProgrammingAssignments/progassgn_1.pdf">Programming Assignment 1</a> </td></tr>
<tr class="r2"><td>
3 </td><td class="c1"> 07-01-2019 </td><td class="c1"> Definition of Horizon, Optimization problem, Shortest path problem, Dijkstra&rsquo;s algorithm </td><td class="c1"> </td></tr>
<tr class="r2"><td>
4 </td><td class="c1"> 10-01-2019 </td><td class="c1"> Optimization problem, illustrative introduction to dynamic programming </td><td class="c1"> </td></tr>
<tr class="r2"><td>
5 </td><td class="c1"> 11-01-2019 </td><td class="c1"> Dynamic programming algorithm, Complexity of dynamic programming </td><td class="c1"> </td></tr>
<tr class="r2"><td>
6 </td><td class="c1"> 14-01-2019 </td><td class="c1"> Dynamic programming examples </td><td class="c1"> </td></tr>
<tr class="r2"><td>
7 </td><td class="c1"> 18-01-2019 </td><td class="c1"> Generalizing the system evolution function </td><td class="c1"> </td></tr>
<tr class="r2"><td>
8 </td><td class="c1"> 19-01-2019 </td><td class="c1"> System evolution using conditional probabilities </td><td class="c1"> <a href="ProgrammingAssignments/progassgn_2.pdf">Programming Assignment 2</a> <br /> <a href="Assignments/Assignment_1.pdf">Assignment 1</a></td></tr>
<tr class="r2"><td>
9 </td><td class="c1"> 19-01-2019 </td><td class="c1"> Markov property </td><td class="c1"> <a href="Notes/Note-19012019.pdf">Note</a> </td></tr>
<tr class="r2"><td>
10 </td><td class="c1"> 24-01-2019 </td><td class="c1"> Examples of Markov chains, Markov chains with actions </td><td class="c1"> </td></tr>
<tr class="r2"><td>
11 </td><td class="c1"> 25-01-2019 </td><td class="c1"> Markov chains with actions, evolution, random rewards </td><td class="c1"> <a href="ProgrammingAssignments/progassgn_3.pdf">Programming Assignment 3</a> </td></tr>
<tr class="r2"><td>
12 </td><td class="c1"> 28-01-2019 </td><td class="c1"> Expected total reward, returns, and discounting </td><td class="c1"> </td></tr>
<tr class="r2"><td>
13 </td><td class="c1"> 31-01-2019 </td><td class="c1"> Markov decision processes - examples </td><td class="c1"> </td></tr>
<tr class="r2"><td>
14 </td><td class="c1"> 01-02-2019 </td><td class="c1"> Solution of 1-horizon problem, Solution of 2-horizon problem, Feedback policies </td><td class="c1"> </td></tr>
<tr class="r2"><td>
</td></tr></table>
<div id="footer">
<div id="footer-text">
Page generated 2019-02-01 16:16:08 IST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
