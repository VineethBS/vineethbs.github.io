# jemdoc: menu{menu}{lectures.html}

= Applied Markov decision processes & Reinforcement Learning (AV499 & AVD871)

~~~
== Textbook and References
- *Richard S. Sutton and Andrew G. Barto. Reinforcement learning: An introduction. MIT press, 2018.*
- Dimitri P. Bertsekas, Dynamic programming and optimal control. Vols. I and II, Athena scientific, 2005.
- Sheldon M. Ross. Applied probability models with optimization applications. Courier Corporation, 2013.
- Sheldon M. Ross. Introduction to stochastic dynamic programming. Academic press, 2014.
- Csaba Szepesv√°ri, Algorithms for Reinforcement Learning, Morgan and Claypool, 2010.
- Dimitri P. Bertsekas, Reinforcement learning and Optimal Control, Athena Scientific, 2019.
- Dimitri P. Bertsekas and John Tsitsiklis - Introduction to Probability
- Bruce Hajek - An exploration of random processes for engineers
- Anurag Kumar - Discrete time stochatic processes (lecture notes for an engineering curriculum)
~~~

== Lecture Schedule
~~~
{}{table}{LectureSchedule}
No | Date | Topic | Homework\/Assignments ||
1 | 03-01-2019 | Introduction and Course Review | ||
2 | 04-01-2019 | Definition of System, Example of an optimization problem, Bellman's optimality criterion | [ProgrammingAssignments/progassgn_1.pdf Programming Assignment 1] ||
3 | 07-01-2019 | Definition of Horizon, Optimization problem, Shortest path problem, Dijkstra's algorithm | ||
4 | 10-01-2019 | Optimization problem, illustrative introduction to dynamic programming | ||
5 | 11-01-2019 | Dynamic programming algorithm, Complexity of dynamic programming | ||
6 | 14-01-2019 | Dynamic programming examples | ||
7 | 18-01-2019 | Generalizing the system evolution function | ||
8 | 19-01-2019 | System evolution using conditional probabilities | ||
9 | 19-01-2019 | Markov property | [Notes/Note-19012019.pdf Note] ||
~~~




